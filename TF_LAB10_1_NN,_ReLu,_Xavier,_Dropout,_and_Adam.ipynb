{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF_LAB10-1_NN, ReLu, Xavier, Dropout, and Adam",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9MCHHeR4yv2crw4PCPWG9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kjcnim/Learned/blob/main/TF_LAB10_1_NN%2C_ReLu%2C_Xavier%2C_Dropout%2C_and_Adam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfDLfefMgEtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de14136-905f-4eb2-f221-6f59a17edbad"
      },
      "source": [
        "#이번 LAB에서는 이전에 MNIST를 다시한번 복습하는 시간을 가진다\r\n",
        "#이후에는 새롭게 배운 방법으로 MNIST의 Accuracy를 높여보도록 한다.\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "learning_rate = 0.001\r\n",
        "\r\n",
        "#batch_size : Total number of training examples present in a single batch\r\n",
        "batch_size = 100\r\n",
        "trainin_epochs = 15\r\n",
        "\r\n",
        "#숫자가 0~9임\r\n",
        "nb_classes = 10\r\n",
        "\r\n",
        "mnist = tf.keras.datasets.mnist\r\n",
        "\r\n",
        "#train과 test set으로 구분지음\r\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n",
        "\r\n",
        "#normalizing data\r\n",
        "#Because of overfitting\r\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\r\n",
        "\r\n",
        "#change data shape\r\n",
        "print(x_train.shape) #(60000, 28, 28)\r\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\r\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\r\n",
        "\r\n",
        "# change result to one-hot encoding\r\n",
        "# in tf1, one_hot= True in read_data_sets(\"MNIST_data/\", one_hot=True)\r\n",
        "# took care of it, but here we need to manually convert them\r\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\r\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\r\n",
        "\r\n",
        "# # Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\r\n",
        "# array([0, 2, 1, 2, 0])\r\n",
        "# `to_categorical` converts this into a matrix with as many columns as there are classes. The number of rows\r\n",
        "#  stays the same. to_categorical(labels)\r\n",
        "# array([[ 1.,  0.,  0.],\r\n",
        "#        [ 0.,  0.,  1.],\r\n",
        "#        [ 0.,  1.,  0.],\r\n",
        "#        [ 0.,  0.,  1.],\r\n",
        "#        [ 1.,  0.,  0.]], dtype=float32)\r\n",
        "\r\n",
        "tf.model = tf.keras.Sequential()\r\n",
        "tf.model.add(tf.keras.layers.Dense(units=10, input_dim = 784, activation = 'softmax'))\r\n",
        "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.Adam(0.001), metrics=['accuracy'])\r\n",
        "tf.model.summary()\r\n",
        "\r\n",
        "history = tf.model.fit(x_train, y_train, batch_size = batch_size, epochs = training_epochs)\r\n",
        "\r\n",
        "\r\n",
        "predictions = tf.model.predict(x_test)\r\n",
        "print('Prediction : \\n', predictions)\r\n",
        "x_train\r\n",
        "score = tf.model.evaluate(x_train, y_train)\r\n",
        "print('Accuracy :', score[1])\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "600/600 [==============================] - 2s 2ms/step - loss: 0.9695 - accuracy: 0.7426\n",
            "Epoch 2/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.3596 - accuracy: 0.9021\n",
            "Epoch 3/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.3110 - accuracy: 0.9146\n",
            "Epoch 4/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2934 - accuracy: 0.9197\n",
            "Epoch 5/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2846 - accuracy: 0.9203\n",
            "Epoch 6/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2679 - accuracy: 0.9260\n",
            "Epoch 7/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2682 - accuracy: 0.9266\n",
            "Epoch 8/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2659 - accuracy: 0.9272\n",
            "Epoch 9/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2623 - accuracy: 0.9271\n",
            "Epoch 10/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2574 - accuracy: 0.9280\n",
            "Epoch 11/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2580 - accuracy: 0.9285\n",
            "Epoch 12/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2490 - accuracy: 0.9316\n",
            "Epoch 13/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2490 - accuracy: 0.9318\n",
            "Epoch 14/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2480 - accuracy: 0.9316\n",
            "Epoch 15/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2457 - accuracy: 0.9316\n",
            "Prediction : \n",
            " [[2.3544796e-06 1.0158637e-11 8.5727424e-06 ... 9.9448735e-01\n",
            "  1.7258079e-05 3.4081741e-04]\n",
            " [1.9321138e-04 1.9022715e-06 9.9531758e-01 ... 6.1585987e-18\n",
            "  2.6997219e-05 3.6523309e-14]\n",
            " [1.6069387e-06 9.7901660e-01 1.2552318e-02 ... 8.3238544e-04\n",
            "  2.9354605e-03 2.3119933e-04]\n",
            " ...\n",
            " [2.3332511e-08 1.2424677e-08 1.0131384e-05 ... 2.9523065e-03\n",
            "  1.0733729e-02 3.2497346e-02]\n",
            " [1.4042328e-07 2.7928289e-07 2.3606376e-07 ... 9.4009351e-08\n",
            "  5.3484598e-03 9.9979133e-08]\n",
            " [1.0962567e-06 3.2239399e-14 7.6623292e-05 ... 1.2499493e-12\n",
            "  2.6809323e-08 6.4954653e-11]]\n",
            "1875/1875 [==============================] - 2s 951us/step - loss: 0.2445 - accuracy: 0.9322\n",
            "Accuracy : 0.9322166442871094\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}